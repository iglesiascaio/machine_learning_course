{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2EL1730: Machine Learning\n",
    "## CentraleSupelec\n",
    "\n",
    "### Lab 7: Deep Neural Network for Hand-written Digit Recognition\n",
    "\n",
    "#### Description\n",
    "\n",
    "The goal of this lab is to implement a deep neural network that utilize convolutional, pooling, dropout and normalization layer in order to solve the task of hand-written digit recognition. For the puprosed of this we are going to utilize `tensorflow` one of the major deep learning frameworks with definitions of the different layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports nessecary libraries\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "#### Loading and Visualizing the MNIST Dataset\n",
    "\n",
    "In order to load the MNIST Dataset we are going to utilize the loader from `keras` within `tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (60000, 28, 28), ' - ', 'x_test shape:', (10000, 28, 28))\n",
      "('y_train shape:', (60000, 10), ' - ', 'y_test shape:', (10000, 10))\n",
      "('Categorical Target:', array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loads the MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalizes data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Converts a class vector (integers) to binary class matrix\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "print('x_train shape:', x_train.shape, ' - ', 'x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape, ' - ', 'y_test shape:', y_test.shape)\n",
    "\n",
    "# Plots and example\n",
    "sample_idx = 12\n",
    "plt.imshow(x_train[sample_idx,...], cmap='gray')\n",
    "print('Categorical Target:', y_train[sample_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "#### Setting up the Deep Neural Network\n",
    "\n",
    "Edit the following linear logistic regression model and change it to the LeNet architecture. You can try different kernel, pooling and stride sizes for the different layers. Documentation about the defined layers can be found here: https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "![LeNet](https://engmrk.com/wp-content/uploads/2018/09/LeNet_Original_Image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The model that you will implement should have the following architecture\n",
    "#1 -> Convolutional layer with 6 kernels and tanh activation function\n",
    "#2 -> Max pooling downsampling the image by 2\n",
    "#3 -> Convolutional layer with 16 kernels and tanh activation function\n",
    "#4 -> Max pooling downsampling the image by 2\n",
    "#5 -> Fully connected layer with 120 units\n",
    "#6 -> Fully connected layer with 84 units\n",
    "#7 -> Fully connected layer with 10 units\n",
    "\n",
    "# Demo Model Definition\n",
    "inp = tf.keras.Input(shape=(28,28))\n",
    "x = tf.keras.layers.Flatten()(inp)\n",
    "out = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Compilation and Training\n",
    "\n",
    "In this part the above model is compiled some the learning parameters are defined and it is trained for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model.compile and model.fit to train the model\n",
    "# loss = categorical_crossentropy , optimizer=sgd\n",
    "# batch_size=64, validation_split=0.2, epochs=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "#### Training Evaluation\n",
    "\n",
    "The learning curves and testing results are calculated and presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b73e2dfd212e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plots the learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Evaluates the trained model on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plots the learning curves\n",
    "[plt.plot(value, label=key) for key,value in history.history.items()]\n",
    "plt.legend()\n",
    "\n",
    "# Evaluates the trained model on the test set. \n",
    "#Use the model.evaluate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the network's predictions and prints the confusion matrix. \n",
    "#Use model.predict function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "#### Print the kernels of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_weights() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "### Modify the initial architecture adding dropout layers and other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "inp = tf.keras.Input(shape=(28,28))\n",
    "x = tf.keras.layers.Flatten()(inp)\n",
    "out = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
