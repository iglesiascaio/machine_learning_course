{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# The first two columns contains the exam scores and the third column\n",
    "# contains the label.\n",
    "data = np.loadtxt('data1.txt', delimiter=',')\n",
    " \n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data \n",
    "pos = np.where(y == 1)\n",
    "neg = np.where(y == 0)\n",
    "plt.scatter(X[pos, 0], X[pos, 1], marker='o', c='b')\n",
    "plt.scatter(X[neg, 0], X[neg, 1], marker='x', c='r')\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')\n",
    "plt.legend(['Admitted', 'Not Admitted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add intercept term to X\n",
    "X_new = np.ones((X.shape[0], 3))\n",
    "X_new[:, 1:] = X\n",
    "X = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #+++++++++++++++++++\n",
    "    return\n",
    "    #+++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(theta):\n",
    "    # Computes the cost of using theta as the parameter \n",
    "    # for logistic regression. \n",
    "    \n",
    "    # YOUR CODE HERE \n",
    "    #+++++++++++++++++++\n",
    "    return\n",
    "    #+++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGrad(theta):\n",
    "    # Computes the gradient of the cost with respect to\n",
    "    # the parameters.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #+++++++++++++++++++\n",
    "    return\n",
    "    #+++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run minimize() to obtain the optimal theta\n",
    "Result = op.minimize(fun=computeCost, x0=initial_theta, \n",
    "                     method = 'TNC', jac=computeGrad);\n",
    "theta = Result.x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "plot_x = np.array([min(X[:, 1]), max(X[:, 1])])\n",
    "plot_y = (- 1.0 / theta[2]) * (theta[1] * plot_x + theta[0])\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.scatter(X[pos, 1], X[pos, 2], marker='o', c='b')\n",
    "plt.scatter(X[neg, 1], X[neg, 2], marker='x', c='r')\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')\n",
    "plt.legend(['Decision Boundary', 'Admitted', 'Not Admitted'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    # Predict whether the label is 0 or 1 using learned logistic \n",
    "    # regression parameters theta. The threshold is set at 0.5\n",
    "    m = X.shape[0] # number of training examples\n",
    "    c = np.zeros(m) # predicted classes of training examples\n",
    "    p = np.zeros(m) # logistic regression outputs of training examples\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #+++++++++++++++++++\n",
    "    \n",
    "    #+++++++++++++++++++\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy on the training set\n",
    "p = predict(np.array(theta), X)\n",
    "counter = 0\n",
    "for i in range(y.size):\n",
    "    if p[i] == y[i]:\n",
    "        counter += 1\n",
    "print('Train Accuracy: {:.2f}'.format(counter / float(y.size) * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
